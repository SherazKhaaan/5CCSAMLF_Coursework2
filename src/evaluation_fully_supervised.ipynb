{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Fully Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42\n",
      "\n",
      "+++ AL Experiment Run 1/3 +++\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sheraz\\anaconda3\\envs\\ml_coursework2\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sheraz\\anaconda3\\envs\\ml_coursework2\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Sheraz\\AppData\\Local\\Temp\\ipykernel_12912\\2612708782.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained SimCLR model for sample selection.\n",
      "\n",
      "=== AL Iteration 1/5, Budget = 10 ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 197\u001b[0m\n\u001b[0;32m    194\u001b[0m     plot_accuracy_vs_budget_over_iterations(budget\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, n_iterations\u001b[38;5;241m=\u001b[39mn_iterations, n_runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 197\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 194\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    192\u001b[0m n_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# For instance, using a budget of 10 samples per iteration and training for 200 epochs per iteration.\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m \u001b[43mplot_accuracy_vs_budget_over_iterations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbudget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 175\u001b[0m, in \u001b[0;36mplot_accuracy_vs_budget_over_iterations\u001b[1;34m(budget, epochs, n_iterations, n_runs)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_runs):\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m+++ AL Experiment Run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_runs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m +++\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 175\u001b[0m     accs \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fully_supervised_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbudget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m     all_runs\u001b[38;5;241m.\u001b[39mappend(accs)\n\u001b[0;32m    177\u001b[0m all_runs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(all_runs)\n",
      "Cell \u001b[1;32mIn[2], line 149\u001b[0m, in \u001b[0;36mrun_fully_supervised_experiment\u001b[1;34m(budget, epochs, n_iterations)\u001b[0m\n\u001b[0;32m    146\u001b[0m unlabeled_subset \u001b[38;5;241m=\u001b[39m Subset(train_dataset, unlabeled_indices)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Select new samples using TPC-RP (Typiclust) from the unlabeled subset.\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m new_selected_local \u001b[38;5;241m=\u001b[39m \u001b[43mselect_samples_typiclust\u001b[49m\u001b[43m(\u001b[49m\u001b[43munlabeled_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimclr_encoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Map local indices back to global indices.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m new_selected_global \u001b[38;5;241m=\u001b[39m [unlabeled_indices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m new_selected_local]\n",
      "Cell \u001b[1;32mIn[2], line 107\u001b[0m, in \u001b[0;36mselect_samples_typiclust\u001b[1;34m(dataset, budget, encoder)\u001b[0m\n\u001b[0;32m    105\u001b[0m all_embeddings, _ \u001b[38;5;241m=\u001b[39m compute_embeddings(encoder, dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Optional visualization of embeddings via t-SNE.\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([label \u001b[38;5;28;01mfor\u001b[39;00m (_, label) \u001b[38;5;129;01min\u001b[39;00m dataset])\n\u001b[0;32m    108\u001b[0m plot_tsne(all_embeddings, all_labels, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt-SNE of CIFAR-10 Embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m)\n\u001b[0;32m    109\u001b[0m selected_indices, cluster_labels \u001b[38;5;241m=\u001b[39m typical_clustering_selection(all_embeddings, budget\u001b[38;5;241m=\u001b[39mbudget, k_nn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 107\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    105\u001b[0m all_embeddings, _ \u001b[38;5;241m=\u001b[39m compute_embeddings(encoder, dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Optional visualization of embeddings via t-SNE.\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([label \u001b[38;5;28;01mfor\u001b[39;00m (_, label) \u001b[38;5;129;01min\u001b[39;00m dataset])\n\u001b[0;32m    108\u001b[0m plot_tsne(all_embeddings, all_labels, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt-SNE of CIFAR-10 Embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m)\n\u001b[0;32m    109\u001b[0m selected_indices, cluster_labels \u001b[38;5;241m=\u001b[39m typical_clustering_selection(all_embeddings, budget\u001b[38;5;241m=\u001b[39mbudget, k_nn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sheraz\\anaconda3\\envs\\ml_coursework2\\lib\\site-packages\\torch\\utils\\data\\dataset.py:412\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[1;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sheraz\\anaconda3\\envs\\ml_coursework2\\lib\\site-packages\\torchvision\\datasets\\cifar.py:119\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    116\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\Sheraz\\anaconda3\\envs\\ml_coursework2\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\Sheraz\\anaconda3\\envs\\ml_coursework2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sheraz\\anaconda3\\envs\\ml_coursework2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Sheraz\\anaconda3\\envs\\ml_coursework2\\lib\\site-packages\\torchvision\\transforms\\transforms.py:681\u001b[0m, in \u001b[0;36mRandomCrop.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    678\u001b[0m     padding \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m height]\n\u001b[0;32m    679\u001b[0m     img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(img, padding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode)\n\u001b[1;32m--> 681\u001b[0m i, j, h, w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcrop(img, i, j, h, w)\n",
      "File \u001b[1;32mc:\\Users\\Sheraz\\anaconda3\\envs\\ml_coursework2\\lib\\site-packages\\torchvision\\transforms\\transforms.py:646\u001b[0m, in \u001b[0;36mRandomCrop.get_params\u001b[1;34m(img, output_size)\u001b[0m\n\u001b[0;32m    643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, h, w\n\u001b[0;32m    645\u001b[0m i \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, h \u001b[38;5;241m-\u001b[39m th \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m--> 646\u001b[0m j \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m i, j, th, tw\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# src/evaluation.py\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.models import resnet18\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Import self-supervised functions and visualization utilities.\n",
    "from typiclust_alg import SimCLRResNet18, compute_embeddings, typical_clustering_selection, DEVICE\n",
    "from visualisation import plot_tsne, set_seed\n",
    "\n",
    "# Set random seed for reproducibility.\n",
    "set_seed(42)\n",
    "\n",
    "def get_cifar10_datasets():\n",
    "    \"\"\"\n",
    "    Loads CIFAR-10 training and test datasets.\n",
    "    For training, uses random crop and horizontal flip (as per Appendix F.2.1).\n",
    "    \"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.247, 0.243, 0.261))\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.247, 0.243, 0.261))\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=True, download=True, transform=train_transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=False, download=True, transform=test_transform)\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def build_cnn_model():\n",
    "    \"\"\"\n",
    "    Builds a ResNet-18 model for fully supervised training.\n",
    "    Re-initializes from scratch for each active learning iteration.\n",
    "    \"\"\"\n",
    "    model = resnet18(pretrained=False)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 10)\n",
    "    return model.to(DEVICE)\n",
    "\n",
    "def train_model_supervised(model, dataloader, epochs, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Trains the model using SGD with momentum and a cosine annealing scheduler.\n",
    "    Hyperparameters follow Appendix F.2.1: initial lr=0.025, momentum=0.9 with Nesterov momentum.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.025, momentum=0.9, nesterov=True)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"[Supervised] Epoch [{epoch+1}/{epochs}] Loss: {avg_loss:.4f}\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, dataloader, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the provided dataloader.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    acc = correct / total\n",
    "    print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "def select_samples_typiclust(dataset, budget, encoder):\n",
    "    \"\"\"\n",
    "    Given a dataset and a pre-loaded SimCLR encoder, compute embeddings and use TPC-RP\n",
    "    to select 'budget' samples.\n",
    "    \"\"\"\n",
    "    all_embeddings, _ = compute_embeddings(encoder, dataset, batch_size=128, num_workers=4)\n",
    "    # Optional visualization of embeddings via t-SNE.\n",
    "    all_labels = np.array([label for (_, label) in dataset])\n",
    "    selected_indices, cluster_labels = typical_clustering_selection(all_embeddings, budget=budget, k_nn=20, random_state=42)\n",
    "    plot_tsne(all_embeddings, cluster_labels, selected_indices=selected_indices, title=\"t-SNE of CIFAR-10 Embeddings with Selected Points\", n_samples=2000)\n",
    "    print(f\"Number of clusters (budget) = {budget}\")\n",
    "    print(f\"Number of typical points selected = {len(selected_indices)}\")\n",
    "    return selected_indices\n",
    "\n",
    "def run_fully_supervised_experiment(budget=10, epochs=200, n_iterations=5):\n",
    "    \"\"\"\n",
    "    Runs the fully supervised active learning experiment.\n",
    "    For each iteration:\n",
    "      1) Select 'budget' new samples from the current unlabeled pool using TPC-RP.\n",
    "      2) Reinitialize and train a new ResNet-18 from scratch on the entire labeled set.\n",
    "      3) Evaluate the model on the test set.\n",
    "    Returns a list of test accuracies across iterations.\n",
    "    \"\"\"\n",
    "    train_dataset, test_dataset = get_cifar10_datasets()\n",
    "    \n",
    "    # Initialize pre-trained SimCLR encoder once for selection.\n",
    "    simclr_encoder = SimCLRResNet18(feature_dim=128).to(DEVICE)\n",
    "    checkpoint_path = 'model/simclr_cifar_10.pth.tar'\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "        state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "        simclr_encoder.load_state_dict(state_dict, strict=False)\n",
    "        print(\"Loaded pretrained SimCLR model for sample selection.\")\n",
    "    else:\n",
    "        print(\"Pretrained checkpoint not found; using untrained encoder for selection.\")\n",
    "    simclr_encoder.eval()\n",
    "\n",
    "    all_indices = set(range(len(train_dataset)))\n",
    "    labeled_indices = []  # Initially, Lâ‚€ is empty.\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    accuracies = []\n",
    "\n",
    "    for it in range(n_iterations):\n",
    "        print(f\"\\n=== AL Iteration {it+1}/{n_iterations}, Budget = {budget} ===\")\n",
    "        # Define the unlabeled pool.\n",
    "        unlabeled_indices = list(all_indices - set(labeled_indices))\n",
    "        unlabeled_subset = Subset(train_dataset, unlabeled_indices)\n",
    "\n",
    "        # Select new samples using TPC-RP (Typiclust) from the unlabeled subset.\n",
    "        new_selected_local = select_samples_typiclust(unlabeled_subset, budget, simclr_encoder)\n",
    "        # Map local indices back to global indices.\n",
    "        new_selected_global = [unlabeled_indices[i] for i in new_selected_local]\n",
    "        labeled_indices.extend(new_selected_global)\n",
    "        print(f\"Total labeled so far: {len(labeled_indices)}\")\n",
    "\n",
    "        # Train a new ResNet-18 from scratch on the accumulated labeled set.\n",
    "        labeled_subset = Subset(train_dataset, labeled_indices)\n",
    "        train_loader = DataLoader(labeled_subset, batch_size=32, shuffle=True)\n",
    "        model = build_cnn_model()  # New model for each iteration.\n",
    "        model = train_model_supervised(model, train_loader, epochs, DEVICE)\n",
    "\n",
    "        # Evaluate on the test set.\n",
    "        acc = evaluate_model(model, test_loader, DEVICE)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "def plot_accuracy_vs_budget_over_iterations(budget, epochs, n_iterations, n_runs=3):\n",
    "    \"\"\"\n",
    "    Runs multiple full active learning experiments (with a fixed budget per iteration)\n",
    "    and plots the average test accuracy over iterations.\n",
    "    \"\"\"\n",
    "    all_runs = []\n",
    "    for run in range(n_runs):\n",
    "        print(f\"\\n+++ AL Experiment Run {run+1}/{n_runs} +++\")\n",
    "        accs = run_fully_supervised_experiment(budget=budget, epochs=epochs, n_iterations=n_iterations)\n",
    "        all_runs.append(accs)\n",
    "    all_runs = np.array(all_runs)\n",
    "    mean_acc = all_runs.mean(axis=0) * 100\n",
    "    std_acc = all_runs.std(axis=0) * 100\n",
    "\n",
    "    iterations = np.arange(1, n_iterations + 1)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.errorbar(iterations, mean_acc, yerr=std_acc, fmt='-o', capsize=5)\n",
    "    plt.xlabel(\"Active Learning Iteration\")\n",
    "    plt.ylabel(\"Test Accuracy (%)\")\n",
    "    plt.title(f\"Fully Supervised AL (Budget per Iteration = {budget})\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Run the fully supervised active learning experiment.\n",
    "    n_iterations = 5\n",
    "    # For instance, using a budget of 10 samples per iteration and training for 200 epochs per iteration.\n",
    "    plot_accuracy_vs_budget_over_iterations(budget=10, epochs=200, n_iterations=n_iterations, n_runs=3)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_coursework2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
