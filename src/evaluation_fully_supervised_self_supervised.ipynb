{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the Fully Supervised with Self-Supervised Embeddings Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# All Imports\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.models import resnet18\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Get the absolute path of the parent directory (main directory)\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Add parent directory to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Device Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# CIFAR-10 Class Names\n",
    "cifar10_labels = {0: \"airplane\", 1: \"automobile\", 2: \"bird\", 3: \"cat\", 4: \"deer\", \n",
    "                   5: \"dog\", 6: \"frog\", 7: \"horse\", 8: \"ship\", 9: \"truck\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 35\n"
     ]
    }
   ],
   "source": [
    "# Ensure reproducibility \n",
    "def set_seed(seed=35):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    print(f\"Random seed set to {seed}\")\n",
    "\n",
    "set_seed(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 30\n",
      "\n",
      "--- Evaluating for Budget = 10, Method = typiclust ---\n",
      "\n",
      "=== Fully Supervised with Self-Supervised Embeddings Evaluation ===\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sheraz\\anaconda3\\envs\\ml_coursework2\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sheraz\\anaconda3\\envs\\ml_coursework2\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Sheraz\\AppData\\Local\\Temp\\ipykernel_30280\\2165487940.py:192: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained SimCLR model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sheraz\\AppData\\Local\\Temp\\ipykernel_30280\\2165487940.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained SimCLR model for TPCRP selection.\n"
     ]
    }
   ],
   "source": [
    "# src/evaluation.py\n",
    "\n",
    "# Import TPCRP (Typiclust) functions from your module.\n",
    "from typiclust_alg import SimCLRResNet18, compute_embeddings, typical_clustering_selection, DEVICE\n",
    "\n",
    "# Import visualization and seed utilities from visualisation.py.\n",
    "from visualisation import plot_tsne, set_seed, plot_selected_images_by_label\n",
    "\n",
    "# Set random seed for reproducibility.\n",
    "set_seed(30)\n",
    "\n",
    "# ---------------------------\n",
    "# Evaluate Linear (Encoder + Linear Head)\n",
    "# ---------------------------\n",
    "def evaluate_linear(encoder, linear_head, dataloader, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Evaluates the combination of the frozen encoder and the trained linear head.\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    linear_head.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            feats = encoder(images)\n",
    "            outputs = linear_head(feats)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    acc = correct / total\n",
    "    print(f\"Linear Evaluation Test Accuracy: {acc*100:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "# ---------------------------\n",
    "# 1. DATASET PREPARATION\n",
    "# ---------------------------\n",
    "def get_cifar10_datasets():\n",
    "    \"\"\"\n",
    "    Loads CIFAR-10 training and test datasets.\n",
    "    For training, uses random crop and horizontal flip (per Appendix F.2.1 for fully supervised training).\n",
    "    \"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.247, 0.243, 0.261))\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.247, 0.243, 0.261))\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=True, download=True, transform=train_transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=False, download=True, transform=test_transform)\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# ---------------------------\n",
    "# 2. (Re)Define TPCRP Functions (if needed) \n",
    "# ---------------------------\n",
    "# (These functions are defined in typiclust.py, so they are re-imported as needed.)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. TRAINING & EVALUATION FUNCTIONS\n",
    "# ---------------------------\n",
    "\n",
    "\n",
    "# (B) Fully Supervised with Self-Supervised Embeddings (Linear Evaluation).\n",
    "def train_linear_classifier(encoder, train_dataset, selected_indices, epochs, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Trains a linear classifier on top of the frozen pre-trained encoder.\n",
    "    Hyperparameters follow Appendix F.2.2: SGD with lr=2.5, momentum=0.9, cosine scheduler.\n",
    "    \"\"\"\n",
    "    subset = Subset(train_dataset, selected_indices)\n",
    "    train_loader = DataLoader(subset, batch_size=32, shuffle=True)\n",
    "    encoder.eval()\n",
    "    for param in encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "    linear_head = nn.Linear(512, 10).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(linear_head.parameters(), lr=2.5, momentum=0.9, nesterov=True)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    linear_head.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                feats = encoder(images)\n",
    "            logits = linear_head(feats)\n",
    "            loss = criterion(logits, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"[Linear Eval] Epoch [{epoch+1}/{epochs}] Loss: {avg_loss:.4f}\")\n",
    "    return linear_head\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 4. SAMPLE SELECTION\n",
    "# ---------------------------\n",
    "def select_samples(train_dataset, budget, method='typiclust'):\n",
    "    import numpy as np\n",
    "    \"\"\"\n",
    "    Selects a subset of samples from the training dataset.\n",
    "    If method == 'typiclust', uses TPCRP; if 'random', selects uniformly.\n",
    "    \"\"\"\n",
    "    if method == 'typiclust':\n",
    "        encoder = SimCLRResNet18(feature_dim=128).to(DEVICE)\n",
    "        checkpoint_path = 'model/simclr_cifar_10.pth.tar'\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "            state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "            encoder.load_state_dict(state_dict, strict=False)\n",
    "            print(\"Loaded pretrained SimCLR model for TPCRP selection.\")\n",
    "        else:\n",
    "            print(\"Pretrained checkpoint not found; TPCRP selection may be affected.\")\n",
    "        encoder.eval()\n",
    "\n",
    "        # 1) Compute embeddings\n",
    "        all_embeddings, _ = compute_embeddings(encoder, train_dataset, batch_size=128, num_workers=4)\n",
    "        \n",
    "        # 2) Perform clustering to find typical samples\n",
    "        selected_indices, cluster_labels = typical_clustering_selection(\n",
    "            all_embeddings, budget=budget, k_nn=20, random_state=30\n",
    "        )\n",
    "        print(\"Unique final selected indices:\", len(set(selected_indices)))\n",
    "        print(\"selected_indices:\", selected_indices)\n",
    "        \n",
    "        # 3) Print info\n",
    "        print(f\"Number of clusters (budget) = {budget}\")\n",
    "        print(f\"Number of typical points selected = {len(selected_indices)}\")\n",
    "        \n",
    "        # Check empty clusters if you wish\n",
    "        import numpy as np\n",
    "        for cluster_id in range(budget):\n",
    "            cluster_idxs = np.where(cluster_labels == cluster_id)[0]\n",
    "            if len(cluster_idxs) == 0:\n",
    "                print(f\"Cluster {cluster_id} is empty.\")\n",
    "\n",
    "        # 4) Now call plot_tsne, passing cluster_labels as the \"cluster_assignments\"\n",
    "        #    and selected_indices as 'selected_indices' so they appear as black X.\n",
    "        plot_tsne(\n",
    "            embeddings=all_embeddings,\n",
    "            cluster_assignments=cluster_labels,   # We color by cluster\n",
    "            selected_indices=selected_indices,     # Mark typical points\n",
    "            title=\"t-SNE of CIFAR-10 Embeddings\",\n",
    "            n_samples=2000\n",
    "        )\n",
    "\n",
    "        # 5) Show the actual images of the selected points in a grid, grouped by label\n",
    "        #   We need the label array for all data: label_array[i] = dataset[i][1].\n",
    "        label_array = np.array([train_dataset[i][1] for i in range(len(train_dataset))])\n",
    "        \n",
    "        # We'll display up to 3 images per label column, for example\n",
    "        plot_selected_images_by_label(\n",
    "            dataset=train_dataset,\n",
    "            selected_indices=selected_indices,\n",
    "            label_array=label_array,\n",
    "            \n",
    "        )\n",
    "\n",
    "        return selected_indices\n",
    "    elif method == 'random':\n",
    "        total_samples = len(train_dataset)\n",
    "        return random.sample(range(total_samples), budget)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'typiclust' or 'random'.\")\n",
    "\n",
    "# ---------------------------\n",
    "# 5. EVALUATION FRAMEWORKS\n",
    "# ---------------------------\n",
    "\n",
    "def evaluate_fully_supervised_self_supervised(method='typiclust', budget=100, epochs=100):\n",
    "    \"\"\"\n",
    "    Fully Supervised with Self-Supervised Embeddings Framework:\n",
    "    Loads a pre-trained SimCLR encoder (frozen), trains a linear classifier on top,\n",
    "    and evaluates the combination on the test set.\n",
    "    Hyperparameters follow Appendix F.2.2.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Fully Supervised with Self-Supervised Embeddings Evaluation ===\")\n",
    "    train_dataset, test_dataset = get_cifar10_datasets()\n",
    "    encoder = SimCLRResNet18(feature_dim=128).to(DEVICE)\n",
    "    checkpoint_path = 'model/simclr_cifar_10.pth.tar'\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "        state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "        encoder.load_state_dict(state_dict, strict=False)\n",
    "        print(\"Loaded pretrained SimCLR model.\")\n",
    "    else:\n",
    "        print(\"Pretrained checkpoint not found; proceeding without pretraining.\")\n",
    "    encoder.eval()\n",
    "    \n",
    "    selected_indices = select_samples(train_dataset, budget, method)\n",
    "    print(f\"Number of training samples selected: {len(selected_indices)}\")\n",
    "    linear_head = train_linear_classifier(encoder, train_dataset, selected_indices, epochs, DEVICE)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    # Use evaluate_linear to combine encoder and linear_head\n",
    "    test_acc = evaluate_linear(encoder, linear_head, test_loader, DEVICE)\n",
    "    return test_acc\n",
    "\n",
    "# ---------------------------\n",
    "# 6. PLOT ACCURACY VS. BUDGET (COMPARISON)\n",
    "# ---------------------------\n",
    "def plot_accuracy_vs_budget_comparison(evaluation_func, budget_list, methods=['typiclust', 'random'], epochs=100):\n",
    "    \"\"\"\n",
    "    Evaluates the fully supervised with self-supervised embeddings evaluation for each method\n",
    "    and plots test accuracy vs. budget for each method on the same graph.\n",
    "    \"\"\"\n",
    "    method_accuracies = {}\n",
    "    for method in methods:\n",
    "        accuracies = []\n",
    "        for budget in budget_list:\n",
    "            print(f\"\\n--- Evaluating for Budget = {budget}, Method = {method} ---\")\n",
    "            acc = evaluation_func(method=method, budget=budget, epochs=epochs)\n",
    "            accuracies.append(acc * 100)  # Convert to percentage\n",
    "        method_accuracies[method] = accuracies\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for method, accuracies in method_accuracies.items():\n",
    "        plt.plot(budget_list, accuracies, marker='o', linestyle='-', label=method)\n",
    "    plt.xlabel(\"Budget (Number of Selected Samples)\")\n",
    "    plt.ylabel(\"Test Accuracy (%)\")\n",
    "    plt.title(\"Test Accuracy vs. Budget Size: Typiclust vs Random\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "# ---------------------------\n",
    "# 7. MAIN FUNCTION\n",
    "# ---------------------------\n",
    "def main():\n",
    "    # Plot accuracy vs. budget for fully supervised with self-supervised embeddings evaluation.\n",
    "    budgets = [10, 20, 30, 40, 50]\n",
    "    plot_accuracy_vs_budget_comparison(evaluate_fully_supervised_self_supervised, budgets, methods=['typiclust', 'random'], epochs=100)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_coursework2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
